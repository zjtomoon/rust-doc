initSidebarItems({"fn":[["__DMB","Data Memory Barrier"],["__DSB","Data Synchronization Barrier"],["__ISB","Instruction Synchronization Barrier"],["__NOP","No Operation"],["__SEV","Send Event"],["__WFE","Wait For Event"],["__WFI","Wait For Interrupt"],["__breakpoint","Inserts a breakpoint instruction."],["__disable_fault_irq","Disable FIQ"],["__disable_irq","Disable IRQ Interrupts"],["__enable_fault_irq","Enable FIQ"],["__enable_irq","Enable IRQ Interrupts"],["__get_APSR","Get APSR Register"],["__get_BASEPRI","Get Base Priority"],["__get_CONTROL","Get Control Register"],["__get_FAULTMASK","Get Fault Mask"],["__get_IPSR","Get IPSR Register"],["__get_MSP","Get Main Stack Pointer"],["__get_PRIMASK","Get Priority Mask"],["__get_PSP","Get Process Stack Pointer"],["__get_xPSR","Get xPSR Register"],["__set_BASEPRI","Set Base Priority"],["__set_BASEPRI_MAX","Set Base Priority with condition"],["__set_CONTROL","Set Control Register"],["__set_FAULTMASK","Set Fault Mask"],["__set_MSP","Set Main Stack Pointer"],["__set_PRIMASK","Set Priority Mask"],["__set_PSP","Set Process Stack Pointer"],["_rev_u16","Reverse the order of the bytes."],["_rev_u32","Reverse the order of the bytes."],["qadd","Signed saturating addition"],["qadd16","Saturating two 16-bit integer additions"],["qadd8","Saturating four 8-bit integer additions"],["qasx","Returns the 16-bit signed saturated equivalent of"],["qsax","Returns the 16-bit signed saturated equivalent of"],["qsub","Signed saturating subtraction"],["qsub16","Saturating two 16-bit integer subtraction"],["qsub8","Saturating two 8-bit integer subtraction"],["sadd16","Returns the 16-bit signed saturated equivalent of"],["sadd8","Returns the 8-bit signed saturated equivalent of"],["sasx","Returns the 16-bit signed equivalent of"],["sel","Select bytes from each operand according to APSR GE flags"],["shadd16","Signed halving parallel halfword-wise addition."],["shadd8","Signed halving parallel byte-wise addition."],["shsub16","Signed halving parallel halfword-wise subtraction."],["shsub8","Signed halving parallel byte-wise subtraction."],["smlad","Dual 16-bit Signed Multiply with Addition of products and 32-bit accumulation."],["smlsd","Dual 16-bit Signed Multiply with Subtraction  of products and 32-bit accumulation and overflow detection."],["smuad","Signed Dual Multiply Add."],["smuadx","Signed Dual Multiply Add Reversed."],["smusd","Signed Dual Multiply Subtract."],["smusdx","Signed Dual Multiply Subtract Reversed."],["usad8","Sum of 8-bit absolute differences."],["usad8a","Sum of 8-bit absolute differences and constant."],["vadd_f32","Vector add."],["vadd_s16","Vector add."],["vadd_s32","Vector add."],["vadd_s8","Vector add."],["vadd_u16","Vector add."],["vadd_u32","Vector add."],["vadd_u8","Vector add."],["vaddl_s16","Vector long add."],["vaddl_s32","Vector long add."],["vaddl_s8","Vector long add."],["vaddl_u16","Vector long add."],["vaddl_u32","Vector long add."],["vaddl_u8","Vector long add."],["vaddq_f32","Vector add."],["vaddq_s16","Vector add."],["vaddq_s32","Vector add."],["vaddq_s64","Vector add."],["vaddq_s8","Vector add."],["vaddq_u16","Vector add."],["vaddq_u32","Vector add."],["vaddq_u64","Vector add."],["vaddq_u8","Vector add."],["vmovl_s16","Vector long move."],["vmovl_s32","Vector long move."],["vmovl_s8","Vector long move."],["vmovl_u16","Vector long move."],["vmovl_u32","Vector long move."],["vmovl_u8","Vector long move."],["vmovn_s16","Vector narrow integer."],["vmovn_s32","Vector narrow integer."],["vmovn_s64","Vector narrow integer."],["vmovn_u16","Vector narrow integer."],["vmovn_u32","Vector narrow integer."],["vmovn_u64","Vector narrow integer."],["vpmax_f32","Folding maximum of adjacent pairs"],["vpmax_s16","Folding maximum of adjacent pairs"],["vpmax_s32","Folding maximum of adjacent pairs"],["vpmax_s8","Folding maximum of adjacent pairs"],["vpmax_u16","Folding maximum of adjacent pairs"],["vpmax_u32","Folding maximum of adjacent pairs"],["vpmax_u8","Folding maximum of adjacent pairs"],["vpmin_f32","Folding minimum of adjacent pairs"],["vpmin_s16","Folding minimum of adjacent pairs"],["vpmin_s32","Folding minimum of adjacent pairs"],["vpmin_s8","Folding minimum of adjacent pairs"],["vpmin_u16","Folding minimum of adjacent pairs"],["vpmin_u32","Folding minimum of adjacent pairs"],["vpmin_u8","Folding minimum of adjacent pairs"],["vrsqrte_f32","Reciprocal square-root estimate."]],"struct":[["float32x2_t","ARM-specific 64-bit wide vector of two packed `f32`."],["float32x4_t","ARM-specific 128-bit wide vector of four packed `f32`."],["int16x2_t","ARM-specific 32-bit wide vector of two packed `i16`."],["int16x4_t","ARM-specific 64-bit wide vector of four packed `i16`."],["int16x8_t","ARM-specific 128-bit wide vector of eight packed `i16`."],["int32x2_t","ARM-specific 64-bit wide vector of two packed `i32`."],["int32x4_t","ARM-specific 128-bit wide vector of four packed `i32`."],["int64x1_t","ARM-specific 64-bit wide vector of one packed `i64`."],["int64x2_t","ARM-specific 128-bit wide vector of two packed `i64`."],["int8x16_t","ARM-specific 128-bit wide vector of sixteen packed `i8`."],["int8x4_t","ARM-specific 32-bit wide vector of four packed `i8`."],["int8x8_t","ARM-specific 64-bit wide vector of eight packed `i8`."],["int8x8x2_t","ARM-specific type containing two `int8x8_t` vectors."],["int8x8x3_t","ARM-specific type containing three `int8x8_t` vectors."],["int8x8x4_t","ARM-specific type containing four `int8x8_t` vectors."],["poly16x4_t","ARM-specific 64-bit wide vector of four packed `u16`."],["poly16x8_t","ARM-specific 128-bit wide vector of eight packed `u16`."],["poly8x16_t","ARM-specific 128-bit wide vector of sixteen packed `u8`."],["poly8x8_t","ARM-specific 64-bit wide polynomial vector of eight packed `u8`."],["poly8x8x2_t","ARM-specific type containing two `poly8x8_t` vectors."],["poly8x8x3_t","ARM-specific type containing three `poly8x8_t` vectors."],["poly8x8x4_t","ARM-specific type containing four `poly8x8_t` vectors."],["uint16x2_t","ARM-specific 32-bit wide vector of two packed `u16`."],["uint16x4_t","ARM-specific 64-bit wide vector of four packed `u16`."],["uint16x8_t","ARM-specific 128-bit wide vector of eight packed `u16`."],["uint32x2_t","ARM-specific 64-bit wide vector of two packed `u32`."],["uint32x4_t","ARM-specific 128-bit wide vector of four packed `u32`."],["uint64x1_t","ARM-specific 64-bit wide vector of one packed `u64`."],["uint64x2_t","ARM-specific 128-bit wide vector of two packed `u64`."],["uint8x16_t","ARM-specific 128-bit wide vector of sixteen packed `u8`."],["uint8x4_t","ARM-specific 32-bit wide vector of four packed `u8`."],["uint8x8_t","ARM-specific 64-bit wide vector of eight packed `u8`."],["uint8x8x2_t","ARM-specific type containing two `uint8x8_t` vectors."],["uint8x8x3_t","ARM-specific type containing three `uint8x8_t` vectors."],["uint8x8x4_t","ARM-specific type containing four `uint8x8_t` vectors."]]});